---
title: Legal and Judicial Evolutions
permalink: /encyclopedia/Legal-and-Judicial-Evolutions-in-countering-disinformation/
nav_order: 12
---

1. [In France: a law against intentional information manipulation](#in-france-a-law-against-intentional-information-manipulation)
2. [In the EU: The Code of Practice on Disinformation](#in-the-eu-the-code-of-practice-on-disinformation)
3. [In the U.S. : Stanford's Global Digital Policy Incubator](#in-the-us--stanfords-global-digital-policy-incubator)

## In France: a law against intentional information manipulation

In France, a law against information manipulation and the **intentional** spread of disinformation was officially adopted on November 20, 2018, nine months after its proposal.

It focuses on massive and rapid spreads of disinformation on social media and more widely digital tools, including foreign state-owned media outlets, and was meant to be especially efficient in electoral contexts.

During said times, the law compels platforms to be more transparent by, for instance, reporting sponsored content as well as the name and invested resources of sponsors. The biggest, most used platforms are to have a legal representative in France and publish their algorithms as open data.

"Fake news" are also formally defined in order to allow for judiciary action. This definition includes massive and artificial diffusion, capacity of disturbance (of public peace or elections), and undeniability of the falsehood of the information being spread.

Outside of election times, platforms ought to cooperate, as well as build and implement open measures to fight disinformation.
The French Superior Council of the Audiovisual (CSA) has been given the authority to hinder or interrupt the broadcasting of foreign state-owned (or state-influenced) TV-services in cases where fundamental national interests are at stake.

## In the EU: The Code of Practice on Disinformation

The Code of Practice was impulsed by the **European Commission**. Signed in September 2018 and entered into force one month later, the Code was developed to achieve objectives already laid out in April of the same year regarding the **spread of disinformation online**, especially on social media platforms ahead of the European elections in May 2019.

Commitment to and implementation of the code work on a **voluntary basis** with **self-regulatory standards**.

⦁	**Signatories**

Singatories include platforms such as Facebook, Twitter, YouTube, but also Google & Mozilla. Beside representatives of online platforms and prominent social networks are advertising industry actors.

⦁	**Scope**

The application of the Code of Practices is limited for each signatory to services provided within the European Economic Area (EEA).

⦁	**Goal**

Overall, signatories must contribute to solutions to challenges raised by disinformation. As explained in the text itself, "_the purpose of this Code is to identify the actions that Signatories could put in place in order to address the challenges related to "Disinformation"_".

Among these actions are efforts towards more transparency, safeguards, scrutiny, a reduced visibility of fake information, an improvement of  the findability of trustworthy content, among others.

⦁	**Defining disinformation**

The Code offers a rather complete definition of disinformation, on which all signatories agree. Excluding "_misleading advertising, reporting errors, satire and parody, or clearly identified partisan news and commentary_", disinformation is defined as "**_verifiably false or misleading information_**" that is "_created, presented and disseminated for **economic gain** or to **intentionally deceive** the public_" ; and that "_may cause **public harm**_" and threatens "_**democratic political and policymaking processes** as well as **public goods** such as the protection of EU citizens' health, the environment or security_".

⦁	**Commitments**

The Code lists a variety of detailed measures to which signatories commit, according to their technical capabilities, the services they provide, their liability regime and "_the role they play in the creation and dissemination of the content at stake_", among other criteria.

Said measures include the **scrutiny of advertising placements** (for instance,  the deployment of policies and processes disrupting "_advertising and monetization incentives for relevant behaviours_") ; the clear and public **disclosure of political advertising and issue-based advertising** (in order to distinguish them from editorial content like news ) ; as well as the **measuring and monitoring of the effectiveness of the Code**.

Moreover, signatories commit to make efforts to **empower consumers and the research community**. Most also engage themselves to putting in place and enforce "_clear policies regarding identity and the misuse of automated bots on their services_".

To help signatories do so, best practices are detailed in the annex of the Code. However, considering the diverse nature of the signatories' operations, purposes, technologies and audiences, the Code is open to various other approaches "_accomplishing the spirit of [its] provisions_".


## In the U.S. : Stanford's Global Digital Policy Incubator

The **Global Digital Policy Incubator**  is a program of the **Center on Democracy, Development and the Rule of Law** (CDDRL), a research center at the **Freeman Spogli Institute for International Studies**, which is a research institute for the study of international affairs at **Stanford University**.

The GDPI was created "_to inspire policy and governance innovations that **reinforce democratic values, universal human rights, and the rule of law in the digital realm**_". It is meant to be a _"**collaboration hub for the development of norms, guidelines, and laws that enhance freedom, security, and trust** in the global digital ecosystem_".

It thus promotes collaboration among various actors, from civil society actors to governments and diplomats to private sector companies, international organizations, technologists and academics.

However, it is aimed at producing solutions and advice specifically for governments and private tech companies in the drafting and making of **policies, norms and processes** which would be beneficial to scoiety as a whole, including citizens. 

As explained on the GDPI website, such policies should "_allow **citizens and society to reap the upside benefits of technology** for economic development and the exercise of **universal human rights**, while **protecting** against the downside risks for personal, national and international **security**_".

In addition to inspiring policies and providing a platform, the GDPI also considers the best ways to **apply** "_these norms and values in a global digital context_" in order to facilitate their development and operability.
